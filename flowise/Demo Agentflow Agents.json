{
  "nodes": [
    {
      "id": "seqStart_0",
      "position": {
        "x": 919,
        "y": 524
      },
      "type": "customNode",
      "data": {
        "id": "seqStart_0",
        "label": "Start",
        "version": 2,
        "name": "seqStart",
        "type": "Start",
        "baseClasses": [
          "Start"
        ],
        "category": "Sequential Agents",
        "description": "Starting point of the conversation",
        "inputParams": [],
        "inputAnchors": [
          {
            "label": "Chat Model",
            "name": "model",
            "type": "BaseChatModel",
            "description": "Only compatible with models that are capable of function calling: ChatOpenAI, ChatMistral, ChatAnthropic, ChatGoogleGenerativeAI, ChatVertexAI, GroqChat",
            "id": "seqStart_0-input-model-BaseChatModel"
          },
          {
            "label": "Agent Memory",
            "name": "agentMemory",
            "type": "BaseCheckpointSaver",
            "description": "Save the state of the agent",
            "optional": true,
            "id": "seqStart_0-input-agentMemory-BaseCheckpointSaver"
          },
          {
            "label": "State",
            "name": "state",
            "type": "State",
            "description": "State is an object that is updated by nodes in the graph, passing from one node to another. By default, state contains \"messages\" that got updated with each message sent and received.",
            "optional": true,
            "id": "seqStart_0-input-state-State"
          },
          {
            "label": "Input Moderation",
            "description": "Detect text that could generate harmful output and prevent it from being sent to the language model",
            "name": "inputModeration",
            "type": "Moderation",
            "optional": true,
            "list": true,
            "id": "seqStart_0-input-inputModeration-Moderation"
          }
        ],
        "inputs": {
          "model": "{{awsChatBedrock_0.data.instance}}",
          "agentMemory": "{{sqliteAgentMemory_0.data.instance}}",
          "state": "{{seqState_0.data.instance}}",
          "inputModeration": ""
        },
        "outputAnchors": [
          {
            "id": "seqStart_0-output-seqStart-Start",
            "name": "seqStart",
            "label": "Start",
            "description": "Starting point of the conversation",
            "type": "Start"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 383,
      "positionAbsolute": {
        "x": 919,
        "y": 524
      },
      "selected": false
    },
    {
      "id": "sqliteAgentMemory_0",
      "position": {
        "x": 180.83833288358983,
        "y": 415.2713833183047
      },
      "type": "customNode",
      "data": {
        "id": "sqliteAgentMemory_0",
        "label": "SQLite Agent Memory",
        "version": 1,
        "name": "sqliteAgentMemory",
        "type": "SQLiteAgentMemory",
        "baseClasses": [
          "SQLiteAgentMemory",
          "BaseCheckpointSaver"
        ],
        "category": "Memory",
        "description": "Memory for agentflow to remember the state of the conversation using SQLite database",
        "inputParams": [
          {
            "label": "Additional Connection Configuration",
            "name": "additionalConfig",
            "type": "json",
            "additionalParams": true,
            "optional": true,
            "id": "sqliteAgentMemory_0-input-additionalConfig-json"
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "additionalConfig": ""
        },
        "outputAnchors": [
          {
            "id": "sqliteAgentMemory_0-output-sqliteAgentMemory-SQLiteAgentMemory|BaseCheckpointSaver",
            "name": "sqliteAgentMemory",
            "label": "SQLiteAgentMemory",
            "description": "Memory for agentflow to remember the state of the conversation using SQLite database",
            "type": "SQLiteAgentMemory | BaseCheckpointSaver"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 253,
      "positionAbsolute": {
        "x": 180.83833288358983,
        "y": 415.2713833183047
      },
      "selected": false
    },
    {
      "id": "awsChatBedrock_0",
      "position": {
        "x": 505.2951151500571,
        "y": -370.8273150395441
      },
      "type": "customNode",
      "data": {
        "id": "awsChatBedrock_0",
        "label": "AWS ChatBedrock",
        "version": 6,
        "name": "awsChatBedrock",
        "type": "AWSChatBedrock",
        "baseClasses": [
          "AWSChatBedrock",
          "BaseChatModel",
          "BaseLanguageModel",
          "Runnable"
        ],
        "category": "Chat Models",
        "description": "Wrapper around AWS Bedrock large language models that use the Converse API",
        "inputParams": [
          {
            "label": "AWS Credential",
            "name": "credential",
            "type": "credential",
            "credentialNames": [
              "awsApi"
            ],
            "optional": true,
            "id": "awsChatBedrock_0-input-credential-credential"
          },
          {
            "label": "Region",
            "name": "region",
            "type": "asyncOptions",
            "loadMethod": "listRegions",
            "default": "us-east-1",
            "id": "awsChatBedrock_0-input-region-asyncOptions"
          },
          {
            "label": "Model Name",
            "name": "model",
            "type": "asyncOptions",
            "loadMethod": "listModels",
            "default": "anthropic.claude-3-haiku-20240307-v1:0",
            "id": "awsChatBedrock_0-input-model-asyncOptions"
          },
          {
            "label": "Custom Model Name",
            "name": "customModel",
            "description": "If provided, will override model selected from Model Name option",
            "type": "string",
            "optional": true,
            "id": "awsChatBedrock_0-input-customModel-string"
          },
          {
            "label": "Streaming",
            "name": "streaming",
            "type": "boolean",
            "default": true,
            "optional": true,
            "additionalParams": true,
            "id": "awsChatBedrock_0-input-streaming-boolean"
          },
          {
            "label": "Temperature",
            "name": "temperature",
            "type": "number",
            "step": 0.1,
            "description": "Temperature parameter may not apply to certain model. Please check available model parameters",
            "optional": true,
            "additionalParams": true,
            "default": 0.7,
            "id": "awsChatBedrock_0-input-temperature-number"
          },
          {
            "label": "Max Tokens to Sample",
            "name": "max_tokens_to_sample",
            "type": "number",
            "step": 10,
            "description": "Max Tokens parameter may not apply to certain model. Please check available model parameters",
            "optional": true,
            "additionalParams": true,
            "default": 200,
            "id": "awsChatBedrock_0-input-max_tokens_to_sample-number"
          },
          {
            "label": "Allow Image Uploads",
            "name": "allowImageUploads",
            "type": "boolean",
            "description": "Allow image input. Refer to the <a href=\"https://docs.flowiseai.com/using-flowise/uploads#image\" target=\"_blank\">docs</a> for more details.",
            "default": false,
            "optional": true,
            "id": "awsChatBedrock_0-input-allowImageUploads-boolean"
          }
        ],
        "inputAnchors": [
          {
            "label": "Cache",
            "name": "cache",
            "type": "BaseCache",
            "optional": true,
            "id": "awsChatBedrock_0-input-cache-BaseCache"
          }
        ],
        "inputs": {
          "cache": "",
          "region": "us-east-1",
          "model": "anthropic.claude-3-haiku-20240307-v1:0",
          "customModel": "",
          "streaming": true,
          "temperature": 0.7,
          "max_tokens_to_sample": 200,
          "allowImageUploads": ""
        },
        "outputAnchors": [
          {
            "id": "awsChatBedrock_0-output-awsChatBedrock-AWSChatBedrock|BaseChatModel|BaseLanguageModel|Runnable",
            "name": "awsChatBedrock",
            "label": "AWSChatBedrock",
            "description": "Wrapper around AWS Bedrock large language models that use the Converse API",
            "type": "AWSChatBedrock | BaseChatModel | BaseLanguageModel | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 766,
      "selected": false,
      "positionAbsolute": {
        "x": 505.2951151500571,
        "y": -370.8273150395441
      },
      "dragging": false
    },
    {
      "id": "seqState_0",
      "position": {
        "x": 172.80549676267023,
        "y": 750.1409320721211
      },
      "type": "customNode",
      "data": {
        "id": "seqState_0",
        "label": "State",
        "version": 2,
        "name": "seqState",
        "type": "State",
        "baseClasses": [
          "State"
        ],
        "category": "Sequential Agents",
        "description": "A centralized state object, updated by nodes in the graph, passing from one node to another",
        "inputParams": [
          {
            "label": "Custom State",
            "name": "stateMemory",
            "type": "tabs",
            "tabIdentifier": "selectedStateTab",
            "additionalParams": true,
            "default": "stateMemoryUI",
            "tabs": [
              {
                "label": "Custom State (Table)",
                "name": "stateMemoryUI",
                "type": "datagrid",
                "description": "Structure for state. By default, state contains \"messages\" that got updated with each message sent and received.",
                "hint": {
                  "label": "How to use",
                  "value": "\nSpecify the Key, Operation Type, and Default Value for the state object. The Operation Type can be either \"Replace\" or \"Append\".\n\n**Replace**\n- Replace the existing value with the new value.\n- If the new value is null, the existing value will be retained.\n\n**Append**\n- Append the new value to the existing value.\n- Default value can be empty or an array. Ex: [\"a\", \"b\"]\n- Final value is an array.\n"
                },
                "datagrid": [
                  {
                    "field": "key",
                    "headerName": "Key",
                    "editable": true
                  },
                  {
                    "field": "type",
                    "headerName": "Operation",
                    "type": "singleSelect",
                    "valueOptions": [
                      "Replace",
                      "Append"
                    ],
                    "editable": true
                  },
                  {
                    "field": "defaultValue",
                    "headerName": "Default Value",
                    "flex": 1,
                    "editable": true
                  }
                ],
                "optional": true,
                "additionalParams": true
              },
              {
                "label": "Custom State (Code)",
                "name": "stateMemoryCode",
                "type": "code",
                "description": "JSON object representing the state",
                "hideCodeExecute": true,
                "codeExample": "{\n    aggregate: {\n        value: (x, y) => x.concat(y), // here we append the new message to the existing messages\n        default: () => []\n    }\n}",
                "optional": true,
                "additionalParams": true
              }
            ],
            "id": "seqState_0-input-stateMemory-tabs"
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "stateMemory": "stateMemoryUI"
        },
        "outputAnchors": [
          {
            "id": "seqState_0-output-seqState-State",
            "name": "seqState",
            "label": "State",
            "description": "A centralized state object, updated by nodes in the graph, passing from one node to another",
            "type": "State"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 253,
      "selected": false,
      "positionAbsolute": {
        "x": 172.80549676267023,
        "y": 750.1409320721211
      },
      "dragging": false
    },
    {
      "id": "seqLLMNode_0",
      "position": {
        "x": 1444.104230067021,
        "y": 429.9889322318837
      },
      "type": "customNode",
      "data": {
        "id": "seqLLMNode_0",
        "label": "LLM Node",
        "version": 4.1,
        "name": "seqLLMNode",
        "type": "LLMNode",
        "baseClasses": [
          "LLMNode"
        ],
        "category": "Sequential Agents",
        "description": "Run Chat Model and return the output",
        "inputParams": [
          {
            "label": "Name",
            "name": "llmNodeName",
            "type": "string",
            "placeholder": "LLM",
            "id": "seqLLMNode_0-input-llmNodeName-string"
          },
          {
            "label": "System Prompt",
            "name": "systemMessagePrompt",
            "type": "string",
            "rows": 4,
            "optional": true,
            "additionalParams": true,
            "id": "seqLLMNode_0-input-systemMessagePrompt-string"
          },
          {
            "label": "Prepend Messages History",
            "name": "messageHistory",
            "description": "Prepend a list of messages between System Prompt and Human Prompt. This is useful when you want to provide few shot examples",
            "type": "code",
            "hideCodeExecute": true,
            "codeExample": "const { AIMessage, HumanMessage, ToolMessage } = require('@langchain/core/messages');\n\nreturn [\n    new HumanMessage(\"What is 333382 🦜 1932?\"),\n    new AIMessage({\n        content: \"\",\n        tool_calls: [\n        {\n            id: \"12345\",\n            name: \"calulator\",\n            args: {\n                number1: 333382,\n                number2: 1932,\n                operation: \"divide\",\n            },\n        },\n        ],\n    }),\n    new ToolMessage({\n        tool_call_id: \"12345\",\n        content: \"The answer is 172.558.\",\n    }),\n    new AIMessage(\"The answer is 172.558.\"),\n]",
            "optional": true,
            "additionalParams": true,
            "id": "seqLLMNode_0-input-messageHistory-code"
          },
          {
            "label": "Conversation History",
            "name": "conversationHistorySelection",
            "type": "options",
            "options": [
              {
                "label": "User Question",
                "name": "user_question",
                "description": "Use the user question from the historical conversation messages as input."
              },
              {
                "label": "Last Conversation Message",
                "name": "last_message",
                "description": "Use the last conversation message from the historical conversation messages as input."
              },
              {
                "label": "All Conversation Messages",
                "name": "all_messages",
                "description": "Use all conversation messages from the historical conversation messages as input."
              },
              {
                "label": "Empty",
                "name": "empty",
                "description": "Do not use any messages from the conversation history. Ensure to use either System Prompt, Human Prompt, or Messages History."
              }
            ],
            "default": "all_messages",
            "optional": true,
            "description": "Select which messages from the conversation history to include in the prompt. The selected messages will be inserted between the System Prompt (if defined) and [Messages History, Human Prompt].",
            "additionalParams": true,
            "id": "seqLLMNode_0-input-conversationHistorySelection-options"
          },
          {
            "label": "Human Prompt",
            "name": "humanMessagePrompt",
            "type": "string",
            "description": "This prompt will be added at the end of the messages as human message",
            "rows": 4,
            "optional": true,
            "additionalParams": true,
            "id": "seqLLMNode_0-input-humanMessagePrompt-string"
          },
          {
            "label": "Format Prompt Values",
            "name": "promptValues",
            "description": "Assign values to the prompt variables. You can also use $flow.state.<variable-name> to get the state value",
            "type": "json",
            "optional": true,
            "acceptVariable": true,
            "list": true,
            "additionalParams": true,
            "id": "seqLLMNode_0-input-promptValues-json"
          },
          {
            "label": "JSON Structured Output",
            "name": "llmStructuredOutput",
            "type": "datagrid",
            "description": "Instruct the LLM to give output in a JSON structured schema",
            "datagrid": [
              {
                "field": "key",
                "headerName": "Key",
                "editable": true
              },
              {
                "field": "type",
                "headerName": "Type",
                "type": "singleSelect",
                "valueOptions": [
                  "String",
                  "String Array",
                  "Number",
                  "Boolean",
                  "Enum"
                ],
                "editable": true
              },
              {
                "field": "enumValues",
                "headerName": "Enum Values",
                "editable": true
              },
              {
                "field": "description",
                "headerName": "Description",
                "flex": 1,
                "editable": true
              }
            ],
            "optional": true,
            "additionalParams": true,
            "id": "seqLLMNode_0-input-llmStructuredOutput-datagrid"
          },
          {
            "label": "Update State",
            "name": "updateStateMemory",
            "type": "tabs",
            "tabIdentifier": "selectedUpdateStateMemoryTab",
            "default": "updateStateMemoryUI",
            "additionalParams": true,
            "tabs": [
              {
                "label": "Update State (Table)",
                "name": "updateStateMemoryUI",
                "type": "datagrid",
                "hint": {
                  "label": "How to use",
                  "value": "\n1. Key and value pair to be updated. For example: if you have the following State:\n    | Key       | Operation     | Default Value     |\n    |-----------|---------------|-------------------|\n    | user      | Replace       |                   |\n\n    You can update the \"user\" value with the following:\n    | Key       | Value     |\n    |-----------|-----------|\n    | user      | john doe  |\n\n2. If you want to use the LLM Node's output as the value to update state, it is available as available as `$flow.output` with the following structure:\n    ```json\n    {\n        \"content\": 'Hello! How can I assist you today?',\n        \"name\": \"\",\n        \"additional_kwargs\": {},\n        \"response_metadata\": {},\n        \"tool_calls\": [],\n        \"invalid_tool_calls\": [],\n        \"usage_metadata\": {}\n    }\n    ```\n\n    For example, if the output `content` is the value you want to update the state with, you can do the following:\n    | Key       | Value                     |\n    |-----------|---------------------------|\n    | user      | `$flow.output.content`  |\n\n3. You can get default flow config, including the current \"state\":\n    - `$flow.sessionId`\n    - `$flow.chatId`\n    - `$flow.chatflowId`\n    - `$flow.input`\n    - `$flow.state`\n\n4. You can get custom variables: `$vars.<variable-name>`\n\n"
                },
                "description": "This is only applicable when you have a custom State at the START node. After agent execution, you might want to update the State values",
                "datagrid": [
                  {
                    "field": "key",
                    "headerName": "Key",
                    "type": "asyncSingleSelect",
                    "loadMethod": "loadStateKeys",
                    "flex": 0.5,
                    "editable": true
                  },
                  {
                    "field": "value",
                    "headerName": "Value",
                    "type": "freeSolo",
                    "valueOptions": [
                      {
                        "label": "LLM Node Output (string)",
                        "value": "$flow.output.content"
                      },
                      {
                        "label": "LLM JSON Output Key (string)",
                        "value": "$flow.output.<replace-with-key>"
                      },
                      {
                        "label": "Global variable (string)",
                        "value": "$vars.<variable-name>"
                      },
                      {
                        "label": "Input Question (string)",
                        "value": "$flow.input"
                      },
                      {
                        "label": "Session Id (string)",
                        "value": "$flow.sessionId"
                      },
                      {
                        "label": "Chat Id (string)",
                        "value": "$flow.chatId"
                      },
                      {
                        "label": "Chatflow Id (string)",
                        "value": "$flow.chatflowId"
                      }
                    ],
                    "editable": true,
                    "flex": 1
                  }
                ],
                "optional": true,
                "additionalParams": true
              },
              {
                "label": "Update State (Code)",
                "name": "updateStateMemoryCode",
                "type": "code",
                "hint": {
                  "label": "How to use",
                  "value": "\n1. Return the key value JSON object. For example: if you have the following State:\n    ```json\n    {\n        \"user\": null\n    }\n    ```\n\n    You can update the \"user\" value by returning the following:\n    ```js\n    return {\n        \"user\": \"john doe\"\n    }\n    ```\n\n2. If you want to use the LLM Node's output as the value to update state, it is available as `$flow.output` with the following structure:\n    ```json\n    {\n        \"content\": 'Hello! How can I assist you today?',\n        \"name\": \"\",\n        \"additional_kwargs\": {},\n        \"response_metadata\": {},\n        \"tool_calls\": [],\n        \"invalid_tool_calls\": [],\n        \"usage_metadata\": {}\n    }\n    ```\n\n    For example, if the output `content` is the value you want to update the state with, you can return the following:\n    ```js\n    return {\n        \"user\": $flow.output.content\n    }\n    ```\n\n3. You can also get default flow config, including the current \"state\":\n    - `$flow.sessionId`\n    - `$flow.chatId`\n    - `$flow.chatflowId`\n    - `$flow.input`\n    - `$flow.state`\n\n4. You can get custom variables: `$vars.<variable-name>`\n\n"
                },
                "description": "This is only applicable when you have a custom State at the START node. After agent execution, you might want to update the State values. Must return an object representing the state",
                "hideCodeExecute": true,
                "codeExample": "const result = $flow.output;\n\n/* Suppose we have a custom State schema like this:\n* {\n    aggregate: {\n        value: (x, y) => x.concat(y),\n        default: () => []\n    }\n  }\n*/\n\nreturn {\n  aggregate: [result.content]\n};",
                "optional": true,
                "additionalParams": true
              }
            ],
            "id": "seqLLMNode_0-input-updateStateMemory-tabs"
          }
        ],
        "inputAnchors": [
          {
            "label": "Sequential Node",
            "name": "sequentialNode",
            "type": "Start | Agent | Condition | LLMNode | ToolNode | CustomFunction | ExecuteFlow",
            "description": "Can be connected to one of the following nodes: Start, Agent, Condition, LLM, Tool Node, Custom Function, Execute Flow",
            "list": true,
            "id": "seqLLMNode_0-input-sequentialNode-Start | Agent | Condition | LLMNode | ToolNode | CustomFunction | ExecuteFlow"
          },
          {
            "label": "Chat Model",
            "name": "model",
            "type": "BaseChatModel",
            "optional": true,
            "description": "Overwrite model to be used for this node",
            "id": "seqLLMNode_0-input-model-BaseChatModel"
          }
        ],
        "inputs": {
          "llmNodeName": "Converstaion",
          "systemMessagePrompt": "You are an expert financial analyst assistant specialized in analyzing company financial reports and statements. Your role is to answer user questions clearly, concisely, and accurately, relying exclusively on the information provided by the retriever tool. Do not incorporate any outside sources, personal assumptions, or general financial knowledge beyond what is explicitly provided. If a query is unclear or ambiguous, ask clarifying questions to ensure accurate understanding before providing an answer.\n\nIf the retrieved information is insufficient to confidently answer the user's query, clearly state that the provided content lacks the necessary details.\n\nPolitely decline to answer queries not directly related to financial reports, company financial statements, or financial analysis.\n",
          "messageHistory": "",
          "conversationHistorySelection": "all_messages",
          "humanMessagePrompt": "Generate a clear, concise, and accurate answer addressing the user's query based exclusively on the chunks retrieved from the provided financial reports and statements. Include relevant figures, metrics, or insights from the retrieved chunks to explicitly support your response. If the retrieved content lacks sufficient detail to fully address the user's query, explicitly state this limitation.\n",
          "sequentialNode": [
            "{{seqStart_0.data.instance}}"
          ],
          "model": "",
          "promptValues": "",
          "llmStructuredOutput": "",
          "updateStateMemory": "updateStateMemoryUI"
        },
        "outputAnchors": [
          {
            "id": "seqLLMNode_0-output-seqLLMNode-LLMNode",
            "name": "seqLLMNode",
            "label": "LLMNode",
            "description": "Run Chat Model and return the output",
            "type": "LLMNode"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 433,
      "selected": false,
      "dragging": false,
      "positionAbsolute": {
        "x": 1444.104230067021,
        "y": 429.9889322318837
      }
    },
    {
      "id": "seqEnd_0",
      "position": {
        "x": 2966.3716128989063,
        "y": 605.705948300438
      },
      "type": "customNode",
      "data": {
        "id": "seqEnd_0",
        "label": "End",
        "version": 2.1,
        "name": "seqEnd",
        "type": "End",
        "baseClasses": [
          "End"
        ],
        "category": "Sequential Agents",
        "description": "End conversation",
        "inputParams": [],
        "inputAnchors": [
          {
            "label": "Sequential Node",
            "name": "sequentialNode",
            "type": "Agent | Condition | LLMNode | ToolNode | CustomFunction | ExecuteFlow",
            "description": "Can be connected to one of the following nodes: Agent, Condition, LLM Node, Tool Node, Custom Function, Execute Flow",
            "id": "seqEnd_0-input-sequentialNode-Agent | Condition | LLMNode | ToolNode | CustomFunction | ExecuteFlow"
          }
        ],
        "inputs": {
          "sequentialNode": "{{seqLLMNode_1.data.instance}}"
        },
        "outputAnchors": [],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 143,
      "selected": false,
      "positionAbsolute": {
        "x": 2966.3716128989063,
        "y": 605.705948300438
      },
      "dragging": false
    },
    {
      "id": "seqToolNode_0",
      "position": {
        "x": 2046.8260153590095,
        "y": 79.97388618395998
      },
      "type": "customNode",
      "data": {
        "id": "seqToolNode_0",
        "label": "Tool Node",
        "version": 2.1,
        "name": "seqToolNode",
        "type": "ToolNode",
        "baseClasses": [
          "ToolNode"
        ],
        "category": "Sequential Agents",
        "description": "Execute tool and return tool's output",
        "inputParams": [
          {
            "label": "Name",
            "name": "toolNodeName",
            "type": "string",
            "placeholder": "Tool",
            "id": "seqToolNode_0-input-toolNodeName-string"
          },
          {
            "label": "Require Approval",
            "name": "interrupt",
            "description": "Require approval before executing tools",
            "type": "boolean",
            "optional": true,
            "id": "seqToolNode_0-input-interrupt-boolean"
          },
          {
            "label": "Approval Prompt",
            "name": "approvalPrompt",
            "description": "Prompt for approval. Only applicable if \"Require Approval\" is enabled",
            "type": "string",
            "default": "You are about to execute tool: {tools}. Ask if user want to proceed",
            "rows": 4,
            "optional": true,
            "additionalParams": true,
            "id": "seqToolNode_0-input-approvalPrompt-string"
          },
          {
            "label": "Approve Button Text",
            "name": "approveButtonText",
            "description": "Text for approve button. Only applicable if \"Require Approval\" is enabled",
            "type": "string",
            "default": "Yes",
            "optional": true,
            "additionalParams": true,
            "id": "seqToolNode_0-input-approveButtonText-string"
          },
          {
            "label": "Reject Button Text",
            "name": "rejectButtonText",
            "description": "Text for reject button. Only applicable if \"Require Approval\" is enabled",
            "type": "string",
            "default": "No",
            "optional": true,
            "additionalParams": true,
            "id": "seqToolNode_0-input-rejectButtonText-string"
          },
          {
            "label": "Update State",
            "name": "updateStateMemory",
            "type": "tabs",
            "tabIdentifier": "selectedUpdateStateMemoryTab",
            "additionalParams": true,
            "default": "updateStateMemoryUI",
            "tabs": [
              {
                "label": "Update State (Table)",
                "name": "updateStateMemoryUI",
                "type": "datagrid",
                "hint": {
                  "label": "How to use",
                  "value": "\n1. Key and value pair to be updated. For example: if you have the following State:\n    | Key       | Operation     | Default Value     |\n    |-----------|---------------|-------------------|\n    | user      | Replace       |                   |\n\n    You can update the \"user\" value with the following:\n    | Key       | Value     |\n    |-----------|-----------|\n    | user      | john doe  |\n\n2. If you want to use the Tool Node's output as the value to update state, it is available as available as `$flow.output` with the following structure (array):\n    ```json\n    [\n        {\n            \"tool\": \"tool's name\",\n            \"toolInput\": {},\n            \"toolOutput\": \"tool's output content\",\n            \"sourceDocuments\": [\n                {\n                    \"pageContent\": \"This is the page content\",\n                    \"metadata\": \"{foo: var}\"\n                }\n            ]\n        }\n    ]\n    ```\n\n    For example:\n    | Key          | Value                                     |\n    |--------------|-------------------------------------------|\n    | sources      | `$flow.output[0].toolOutput`       |\n\n3. You can get default flow config, including the current \"state\":\n    - `$flow.sessionId`\n    - `$flow.chatId`\n    - `$flow.chatflowId`\n    - `$flow.input`\n    - `$flow.state`\n\n4. You can get custom variables: `$vars.<variable-name>`\n\n"
                },
                "description": "This is only applicable when you have a custom State at the START node. After tool execution, you might want to update the State values",
                "datagrid": [
                  {
                    "field": "key",
                    "headerName": "Key",
                    "type": "asyncSingleSelect",
                    "loadMethod": "loadStateKeys",
                    "flex": 0.5,
                    "editable": true
                  },
                  {
                    "field": "value",
                    "headerName": "Value",
                    "type": "freeSolo",
                    "valueOptions": [
                      {
                        "label": "All Tools Output (array)",
                        "value": "$flow.output"
                      },
                      {
                        "label": "First Tool Output (string)",
                        "value": "$flow.output[0].toolOutput"
                      },
                      {
                        "label": "First Tool Input Arguments (string | json)",
                        "value": "$flow.output[0].toolInput"
                      },
                      {
                        "label": "First Tool Returned Source Documents (array)",
                        "value": "$flow.output[0].sourceDocuments"
                      },
                      {
                        "label": "Global variable (string)",
                        "value": "$vars.<variable-name>"
                      },
                      {
                        "label": "Input Question (string)",
                        "value": "$flow.input"
                      },
                      {
                        "label": "Session Id (string)",
                        "value": "$flow.sessionId"
                      },
                      {
                        "label": "Chat Id (string)",
                        "value": "$flow.chatId"
                      },
                      {
                        "label": "Chatflow Id (string)",
                        "value": "$flow.chatflowId"
                      }
                    ],
                    "editable": true,
                    "flex": 1
                  }
                ],
                "optional": true,
                "additionalParams": true
              },
              {
                "label": "Update State (Code)",
                "name": "updateStateMemoryCode",
                "type": "code",
                "hint": {
                  "label": "How to use",
                  "value": "\n1. Return the key value JSON object. For example: if you have the following State:\n    ```json\n    {\n        \"user\": null\n    }\n    ```\n\n    You can update the \"user\" value by returning the following:\n    ```js\n    return {\n        \"user\": \"john doe\"\n    }\n    ```\n\n2. If you want to use the tool's output as the value to update state, it is available as `$flow.output` with the following structure (array):\n    ```json\n    [\n        {\n            \"tool\": \"tool's name\",\n            \"toolInput\": {},\n            \"toolOutput\": \"tool's output content\",\n            \"sourceDocuments\": [\n                {\n                    \"pageContent\": \"This is the page content\",\n                    \"metadata\": \"{foo: var}\"\n                }\n            ]\n        }\n    ]\n    ```\n\n    For example:\n    ```js\n    /* Assuming you have the following state:\n    {\n        \"sources\": null\n    }\n    */\n    \n    return {\n        \"sources\": $flow.output[0].toolOutput\n    }\n    ```\n\n3. You can also get default flow config, including the current \"state\":\n    - `$flow.sessionId`\n    - `$flow.chatId`\n    - `$flow.chatflowId`\n    - `$flow.input`\n    - `$flow.state`\n\n4. You can get custom variables: `$vars.<variable-name>`\n\n"
                },
                "description": "This is only applicable when you have a custom State at the START node. After tool execution, you might want to update the State values. Must return an object representing the state",
                "hideCodeExecute": true,
                "codeExample": "const result = $flow.output;\n\n/* Suppose we have a custom State schema like this:\n* {\n    aggregate: {\n        value: (x, y) => x.concat(y),\n        default: () => []\n    }\n  }\n*/\n\nreturn {\n  aggregate: [result.content]\n};",
                "optional": true,
                "additionalParams": true
              }
            ],
            "id": "seqToolNode_0-input-updateStateMemory-tabs"
          }
        ],
        "inputAnchors": [
          {
            "label": "Tools",
            "name": "tools",
            "type": "Tool",
            "list": true,
            "optional": true,
            "id": "seqToolNode_0-input-tools-Tool"
          },
          {
            "label": "LLM Node",
            "name": "llmNode",
            "type": "LLMNode",
            "id": "seqToolNode_0-input-llmNode-LLMNode"
          }
        ],
        "inputs": {
          "tools": [
            "{{retrieverTool_0.data.instance}}"
          ],
          "llmNode": "{{seqLLMNode_0.data.instance}}",
          "toolNodeName": "Tools",
          "interrupt": "",
          "approvalPrompt": "You are about to execute tool: {tools}. Ask if user want to proceed",
          "approveButtonText": "Yes",
          "rejectButtonText": "No",
          "updateStateMemory": "updateStateMemoryUI"
        },
        "outputAnchors": [
          {
            "id": "seqToolNode_0-output-seqToolNode-ToolNode",
            "name": "seqToolNode",
            "label": "ToolNode",
            "description": "Execute tool and return tool's output",
            "type": "ToolNode"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 529,
      "positionAbsolute": {
        "x": 2046.8260153590095,
        "y": 79.97388618395998
      },
      "selected": false,
      "dragging": false
    },
    {
      "id": "awsBedrockKBRetriever_0",
      "position": {
        "x": 1135.6661679923209,
        "y": -278.5467835396697
      },
      "type": "customNode",
      "data": {
        "id": "awsBedrockKBRetriever_0",
        "label": "AWS Bedrock Knowledge Base Retriever",
        "version": 1,
        "name": "awsBedrockKBRetriever",
        "type": "AWSBedrockKBRetriever",
        "baseClasses": [
          "AWSBedrockKBRetriever",
          "BaseRetriever"
        ],
        "category": "Retrievers",
        "description": "Connect to AWS Bedrock Knowledge Base API and retrieve relevant chunks",
        "inputParams": [
          {
            "label": "AWS Credential",
            "name": "credential",
            "type": "credential",
            "credentialNames": [
              "awsApi"
            ],
            "optional": true,
            "id": "awsBedrockKBRetriever_0-input-credential-credential"
          },
          {
            "label": "Region",
            "name": "region",
            "type": "asyncOptions",
            "loadMethod": "listRegions",
            "default": "us-east-1",
            "id": "awsBedrockKBRetriever_0-input-region-asyncOptions"
          },
          {
            "label": "Knowledge Base ID",
            "name": "knoledgeBaseID",
            "type": "string",
            "id": "awsBedrockKBRetriever_0-input-knoledgeBaseID-string"
          },
          {
            "label": "Query",
            "name": "query",
            "type": "string",
            "description": "Query to retrieve documents from retriever. If not specified, user question will be used",
            "optional": true,
            "acceptVariable": true,
            "id": "awsBedrockKBRetriever_0-input-query-string"
          },
          {
            "label": "TopK",
            "name": "topK",
            "type": "number",
            "description": "Number of chunks to retrieve",
            "optional": true,
            "additionalParams": true,
            "default": 5,
            "id": "awsBedrockKBRetriever_0-input-topK-number"
          },
          {
            "label": "SearchType",
            "name": "searchType",
            "type": "options",
            "description": "Knowledge Base search type. Possible values are HYBRID and SEMANTIC. If not specified, default will be used. Consult AWS documentation for more",
            "options": [
              {
                "label": "HYBRID",
                "name": "HYBRID",
                "description": "Hybrid seach type"
              },
              {
                "label": "SEMANTIC",
                "name": "SEMANTIC",
                "description": "Semantic seach type"
              }
            ],
            "optional": true,
            "additionalParams": true,
            "id": "awsBedrockKBRetriever_0-input-searchType-options"
          },
          {
            "label": "Filter",
            "name": "filter",
            "type": "string",
            "description": "Knowledge Base retrieval filter. Read documentation for filter syntax",
            "optional": true,
            "additionalParams": true,
            "id": "awsBedrockKBRetriever_0-input-filter-string"
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "region": "us-east-1",
          "knoledgeBaseID": "JCH9MFUXLB",
          "query": "",
          "topK": 5,
          "searchType": "",
          "filter": ""
        },
        "outputAnchors": [
          {
            "id": "awsBedrockKBRetriever_0-output-awsBedrockKBRetriever-AWSBedrockKBRetriever|BaseRetriever",
            "name": "awsBedrockKBRetriever",
            "label": "AWSBedrockKBRetriever",
            "description": "Connect to AWS Bedrock Knowledge Base API and retrieve relevant chunks",
            "type": "AWSBedrockKBRetriever | BaseRetriever"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 622,
      "selected": false,
      "dragging": false,
      "positionAbsolute": {
        "x": 1135.6661679923209,
        "y": -278.5467835396697
      }
    },
    {
      "id": "retrieverTool_0",
      "position": {
        "x": 1596.4306525893867,
        "y": -388.00356967791697
      },
      "type": "customNode",
      "data": {
        "id": "retrieverTool_0",
        "label": "Retriever Tool",
        "version": 3,
        "name": "retrieverTool",
        "type": "RetrieverTool",
        "baseClasses": [
          "RetrieverTool",
          "DynamicTool",
          "Tool",
          "StructuredTool",
          "Runnable"
        ],
        "category": "Tools",
        "description": "Use a retriever as allowed tool for agent",
        "inputParams": [
          {
            "label": "Retriever Name",
            "name": "name",
            "type": "string",
            "placeholder": "search_state_of_union",
            "id": "retrieverTool_0-input-name-string"
          },
          {
            "label": "Retriever Description",
            "name": "description",
            "type": "string",
            "description": "When should agent uses to retrieve documents",
            "rows": 3,
            "placeholder": "Searches and returns documents regarding the state-of-the-union.",
            "id": "retrieverTool_0-input-description-string"
          },
          {
            "label": "Return Source Documents",
            "name": "returnSourceDocuments",
            "type": "boolean",
            "optional": true,
            "id": "retrieverTool_0-input-returnSourceDocuments-boolean"
          },
          {
            "label": "Additional Metadata Filter",
            "name": "retrieverToolMetadataFilter",
            "type": "json",
            "description": "Add additional metadata filter on top of the existing filter from vector store",
            "optional": true,
            "additionalParams": true,
            "hint": {
              "label": "What can you filter?",
              "value": "Add additional filters to vector store. You can also filter with flow config, including the current \"state\":\n- `$flow.sessionId`\n- `$flow.chatId`\n- `$flow.chatflowId`\n- `$flow.input`\n- `$flow.state`\n"
            },
            "id": "retrieverTool_0-input-retrieverToolMetadataFilter-json"
          }
        ],
        "inputAnchors": [
          {
            "label": "Retriever",
            "name": "retriever",
            "type": "BaseRetriever",
            "id": "retrieverTool_0-input-retriever-BaseRetriever"
          }
        ],
        "inputs": {
          "name": "KB_retriever",
          "description": "Use the provided tool to look for relevant information and answer the user's question to the best of your ability. Be concise in your responses.\n\nIf you can't find a document relevant to the user's question, never make a guess or make up an answer, but let the user know that you failed to find relevant information.",
          "retriever": "{{awsBedrockKBRetriever_0.data.instance}}",
          "returnSourceDocuments": false,
          "retrieverToolMetadataFilter": ""
        },
        "outputAnchors": [
          {
            "id": "retrieverTool_0-output-retrieverTool-RetrieverTool|DynamicTool|Tool|StructuredTool|Runnable",
            "name": "retrieverTool",
            "label": "RetrieverTool",
            "description": "Use a retriever as allowed tool for agent",
            "type": "RetrieverTool | DynamicTool | Tool | StructuredTool | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 656,
      "selected": false,
      "positionAbsolute": {
        "x": 1596.4306525893867,
        "y": -388.00356967791697
      },
      "dragging": false
    },
    {
      "id": "seqLLMNode_1",
      "position": {
        "x": 2442.8718816559463,
        "y": 284.1091284181021
      },
      "type": "customNode",
      "data": {
        "id": "seqLLMNode_1",
        "label": "LLM Node",
        "version": 4.1,
        "name": "seqLLMNode",
        "type": "LLMNode",
        "baseClasses": [
          "LLMNode"
        ],
        "category": "Sequential Agents",
        "description": "Run Chat Model and return the output",
        "inputParams": [
          {
            "label": "Name",
            "name": "llmNodeName",
            "type": "string",
            "placeholder": "LLM",
            "id": "seqLLMNode_1-input-llmNodeName-string"
          },
          {
            "label": "System Prompt",
            "name": "systemMessagePrompt",
            "type": "string",
            "rows": 4,
            "optional": true,
            "additionalParams": true,
            "id": "seqLLMNode_1-input-systemMessagePrompt-string"
          },
          {
            "label": "Prepend Messages History",
            "name": "messageHistory",
            "description": "Prepend a list of messages between System Prompt and Human Prompt. This is useful when you want to provide few shot examples",
            "type": "code",
            "hideCodeExecute": true,
            "codeExample": "const { AIMessage, HumanMessage, ToolMessage } = require('@langchain/core/messages');\n\nreturn [\n    new HumanMessage(\"What is 333382 🦜 1932?\"),\n    new AIMessage({\n        content: \"\",\n        tool_calls: [\n        {\n            id: \"12345\",\n            name: \"calulator\",\n            args: {\n                number1: 333382,\n                number2: 1932,\n                operation: \"divide\",\n            },\n        },\n        ],\n    }),\n    new ToolMessage({\n        tool_call_id: \"12345\",\n        content: \"The answer is 172.558.\",\n    }),\n    new AIMessage(\"The answer is 172.558.\"),\n]",
            "optional": true,
            "additionalParams": true,
            "id": "seqLLMNode_1-input-messageHistory-code"
          },
          {
            "label": "Conversation History",
            "name": "conversationHistorySelection",
            "type": "options",
            "options": [
              {
                "label": "User Question",
                "name": "user_question",
                "description": "Use the user question from the historical conversation messages as input."
              },
              {
                "label": "Last Conversation Message",
                "name": "last_message",
                "description": "Use the last conversation message from the historical conversation messages as input."
              },
              {
                "label": "All Conversation Messages",
                "name": "all_messages",
                "description": "Use all conversation messages from the historical conversation messages as input."
              },
              {
                "label": "Empty",
                "name": "empty",
                "description": "Do not use any messages from the conversation history. Ensure to use either System Prompt, Human Prompt, or Messages History."
              }
            ],
            "default": "all_messages",
            "optional": true,
            "description": "Select which messages from the conversation history to include in the prompt. The selected messages will be inserted between the System Prompt (if defined) and [Messages History, Human Prompt].",
            "additionalParams": true,
            "id": "seqLLMNode_1-input-conversationHistorySelection-options"
          },
          {
            "label": "Human Prompt",
            "name": "humanMessagePrompt",
            "type": "string",
            "description": "This prompt will be added at the end of the messages as human message",
            "rows": 4,
            "optional": true,
            "additionalParams": true,
            "id": "seqLLMNode_1-input-humanMessagePrompt-string"
          },
          {
            "label": "Format Prompt Values",
            "name": "promptValues",
            "description": "Assign values to the prompt variables. You can also use $flow.state.<variable-name> to get the state value",
            "type": "json",
            "optional": true,
            "acceptVariable": true,
            "list": true,
            "additionalParams": true,
            "id": "seqLLMNode_1-input-promptValues-json"
          },
          {
            "label": "JSON Structured Output",
            "name": "llmStructuredOutput",
            "type": "datagrid",
            "description": "Instruct the LLM to give output in a JSON structured schema",
            "datagrid": [
              {
                "field": "key",
                "headerName": "Key",
                "editable": true
              },
              {
                "field": "type",
                "headerName": "Type",
                "type": "singleSelect",
                "valueOptions": [
                  "String",
                  "String Array",
                  "Number",
                  "Boolean",
                  "Enum"
                ],
                "editable": true
              },
              {
                "field": "enumValues",
                "headerName": "Enum Values",
                "editable": true
              },
              {
                "field": "description",
                "headerName": "Description",
                "flex": 1,
                "editable": true
              }
            ],
            "optional": true,
            "additionalParams": true,
            "id": "seqLLMNode_1-input-llmStructuredOutput-datagrid"
          },
          {
            "label": "Update State",
            "name": "updateStateMemory",
            "type": "tabs",
            "tabIdentifier": "selectedUpdateStateMemoryTab",
            "default": "updateStateMemoryUI",
            "additionalParams": true,
            "tabs": [
              {
                "label": "Update State (Table)",
                "name": "updateStateMemoryUI",
                "type": "datagrid",
                "hint": {
                  "label": "How to use",
                  "value": "\n1. Key and value pair to be updated. For example: if you have the following State:\n    | Key       | Operation     | Default Value     |\n    |-----------|---------------|-------------------|\n    | user      | Replace       |                   |\n\n    You can update the \"user\" value with the following:\n    | Key       | Value     |\n    |-----------|-----------|\n    | user      | john doe  |\n\n2. If you want to use the LLM Node's output as the value to update state, it is available as available as `$flow.output` with the following structure:\n    ```json\n    {\n        \"content\": 'Hello! How can I assist you today?',\n        \"name\": \"\",\n        \"additional_kwargs\": {},\n        \"response_metadata\": {},\n        \"tool_calls\": [],\n        \"invalid_tool_calls\": [],\n        \"usage_metadata\": {}\n    }\n    ```\n\n    For example, if the output `content` is the value you want to update the state with, you can do the following:\n    | Key       | Value                     |\n    |-----------|---------------------------|\n    | user      | `$flow.output.content`  |\n\n3. You can get default flow config, including the current \"state\":\n    - `$flow.sessionId`\n    - `$flow.chatId`\n    - `$flow.chatflowId`\n    - `$flow.input`\n    - `$flow.state`\n\n4. You can get custom variables: `$vars.<variable-name>`\n\n"
                },
                "description": "This is only applicable when you have a custom State at the START node. After agent execution, you might want to update the State values",
                "datagrid": [
                  {
                    "field": "key",
                    "headerName": "Key",
                    "type": "asyncSingleSelect",
                    "loadMethod": "loadStateKeys",
                    "flex": 0.5,
                    "editable": true
                  },
                  {
                    "field": "value",
                    "headerName": "Value",
                    "type": "freeSolo",
                    "valueOptions": [
                      {
                        "label": "LLM Node Output (string)",
                        "value": "$flow.output.content"
                      },
                      {
                        "label": "LLM JSON Output Key (string)",
                        "value": "$flow.output.<replace-with-key>"
                      },
                      {
                        "label": "Global variable (string)",
                        "value": "$vars.<variable-name>"
                      },
                      {
                        "label": "Input Question (string)",
                        "value": "$flow.input"
                      },
                      {
                        "label": "Session Id (string)",
                        "value": "$flow.sessionId"
                      },
                      {
                        "label": "Chat Id (string)",
                        "value": "$flow.chatId"
                      },
                      {
                        "label": "Chatflow Id (string)",
                        "value": "$flow.chatflowId"
                      }
                    ],
                    "editable": true,
                    "flex": 1
                  }
                ],
                "optional": true,
                "additionalParams": true
              },
              {
                "label": "Update State (Code)",
                "name": "updateStateMemoryCode",
                "type": "code",
                "hint": {
                  "label": "How to use",
                  "value": "\n1. Return the key value JSON object. For example: if you have the following State:\n    ```json\n    {\n        \"user\": null\n    }\n    ```\n\n    You can update the \"user\" value by returning the following:\n    ```js\n    return {\n        \"user\": \"john doe\"\n    }\n    ```\n\n2. If you want to use the LLM Node's output as the value to update state, it is available as `$flow.output` with the following structure:\n    ```json\n    {\n        \"content\": 'Hello! How can I assist you today?',\n        \"name\": \"\",\n        \"additional_kwargs\": {},\n        \"response_metadata\": {},\n        \"tool_calls\": [],\n        \"invalid_tool_calls\": [],\n        \"usage_metadata\": {}\n    }\n    ```\n\n    For example, if the output `content` is the value you want to update the state with, you can return the following:\n    ```js\n    return {\n        \"user\": $flow.output.content\n    }\n    ```\n\n3. You can also get default flow config, including the current \"state\":\n    - `$flow.sessionId`\n    - `$flow.chatId`\n    - `$flow.chatflowId`\n    - `$flow.input`\n    - `$flow.state`\n\n4. You can get custom variables: `$vars.<variable-name>`\n\n"
                },
                "description": "This is only applicable when you have a custom State at the START node. After agent execution, you might want to update the State values. Must return an object representing the state",
                "hideCodeExecute": true,
                "codeExample": "const result = $flow.output;\n\n/* Suppose we have a custom State schema like this:\n* {\n    aggregate: {\n        value: (x, y) => x.concat(y),\n        default: () => []\n    }\n  }\n*/\n\nreturn {\n  aggregate: [result.content]\n};",
                "optional": true,
                "additionalParams": true
              }
            ],
            "id": "seqLLMNode_1-input-updateStateMemory-tabs"
          }
        ],
        "inputAnchors": [
          {
            "label": "Sequential Node",
            "name": "sequentialNode",
            "type": "Start | Agent | Condition | LLMNode | ToolNode | CustomFunction | ExecuteFlow",
            "description": "Can be connected to one of the following nodes: Start, Agent, Condition, LLM, Tool Node, Custom Function, Execute Flow",
            "list": true,
            "id": "seqLLMNode_1-input-sequentialNode-Start | Agent | Condition | LLMNode | ToolNode | CustomFunction | ExecuteFlow"
          },
          {
            "label": "Chat Model",
            "name": "model",
            "type": "BaseChatModel",
            "optional": true,
            "description": "Overwrite model to be used for this node",
            "id": "seqLLMNode_1-input-model-BaseChatModel"
          }
        ],
        "inputs": {
          "llmNodeName": "Content Rewriter",
          "systemMessagePrompt": "As a Content Rewriter, your role is to ensure that the information provided to users is relevant, accurate, and easy to understand. You are responsible for rewriting the content retrieved ensuring it aligns with the user's query and expectations. Your expertise is vital in maintaining the quality and reliability of the information shared with users, and in structuring it clearly where appropriate.\n\nInstructions:\n\n* Review & rewrite: Review the response provided by the Knowledge Base. Compile the answer based on the content found ensuring its accuracy and clarity, ensure all communication is clear, professional, friendly, and helpful. If the content is irrelevant, incomplete, or unclear, inform the user about a failure to find relevant information and suggest rephrasing the question. Tailor the tone based on user needs, prioritizing clarity and a positive experience.",
          "messageHistory": "",
          "conversationHistorySelection": "all_messages",
          "humanMessagePrompt": "",
          "sequentialNode": [
            "{{seqToolNode_0.data.instance}}"
          ],
          "model": "",
          "promptValues": "",
          "llmStructuredOutput": "",
          "updateStateMemory": "updateStateMemoryUI"
        },
        "outputAnchors": [
          {
            "id": "seqLLMNode_1-output-seqLLMNode-LLMNode",
            "name": "seqLLMNode",
            "label": "LLMNode",
            "description": "Run Chat Model and return the output",
            "type": "LLMNode"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 433,
      "selected": false,
      "dragging": false,
      "positionAbsolute": {
        "x": 2442.8718816559463,
        "y": 284.1091284181021
      }
    }
  ],
  "edges": [
    {
      "source": "sqliteAgentMemory_0",
      "sourceHandle": "sqliteAgentMemory_0-output-sqliteAgentMemory-SQLiteAgentMemory|BaseCheckpointSaver",
      "target": "seqStart_0",
      "targetHandle": "seqStart_0-input-agentMemory-BaseCheckpointSaver",
      "type": "buttonedge",
      "id": "sqliteAgentMemory_0-sqliteAgentMemory_0-output-sqliteAgentMemory-SQLiteAgentMemory|BaseCheckpointSaver-seqStart_0-seqStart_0-input-agentMemory-BaseCheckpointSaver"
    },
    {
      "source": "awsChatBedrock_0",
      "sourceHandle": "awsChatBedrock_0-output-awsChatBedrock-AWSChatBedrock|BaseChatModel|BaseLanguageModel|Runnable",
      "target": "seqStart_0",
      "targetHandle": "seqStart_0-input-model-BaseChatModel",
      "type": "buttonedge",
      "id": "awsChatBedrock_0-awsChatBedrock_0-output-awsChatBedrock-AWSChatBedrock|BaseChatModel|BaseLanguageModel|Runnable-seqStart_0-seqStart_0-input-model-BaseChatModel"
    },
    {
      "source": "seqState_0",
      "sourceHandle": "seqState_0-output-seqState-State",
      "target": "seqStart_0",
      "targetHandle": "seqStart_0-input-state-State",
      "type": "buttonedge",
      "id": "seqState_0-seqState_0-output-seqState-State-seqStart_0-seqStart_0-input-state-State"
    },
    {
      "source": "seqStart_0",
      "sourceHandle": "seqStart_0-output-seqStart-Start",
      "target": "seqLLMNode_0",
      "targetHandle": "seqLLMNode_0-input-sequentialNode-Start | Agent | Condition | LLMNode | ToolNode | CustomFunction | ExecuteFlow",
      "type": "buttonedge",
      "id": "seqStart_0-seqStart_0-output-seqStart-Start-seqLLMNode_0-seqLLMNode_0-input-sequentialNode-Start | Agent | Condition | LLMNode | ToolNode | CustomFunction | ExecuteFlow"
    },
    {
      "source": "seqLLMNode_0",
      "sourceHandle": "seqLLMNode_0-output-seqLLMNode-LLMNode",
      "target": "seqToolNode_0",
      "targetHandle": "seqToolNode_0-input-llmNode-LLMNode",
      "type": "buttonedge",
      "id": "seqLLMNode_0-seqLLMNode_0-output-seqLLMNode-LLMNode-seqToolNode_0-seqToolNode_0-input-llmNode-LLMNode"
    },
    {
      "source": "awsBedrockKBRetriever_0",
      "sourceHandle": "awsBedrockKBRetriever_0-output-awsBedrockKBRetriever-AWSBedrockKBRetriever|BaseRetriever",
      "target": "retrieverTool_0",
      "targetHandle": "retrieverTool_0-input-retriever-BaseRetriever",
      "type": "buttonedge",
      "id": "awsBedrockKBRetriever_0-awsBedrockKBRetriever_0-output-awsBedrockKBRetriever-AWSBedrockKBRetriever|BaseRetriever-retrieverTool_0-retrieverTool_0-input-retriever-BaseRetriever"
    },
    {
      "source": "retrieverTool_0",
      "sourceHandle": "retrieverTool_0-output-retrieverTool-RetrieverTool|DynamicTool|Tool|StructuredTool|Runnable",
      "target": "seqToolNode_0",
      "targetHandle": "seqToolNode_0-input-tools-Tool",
      "type": "buttonedge",
      "id": "retrieverTool_0-retrieverTool_0-output-retrieverTool-RetrieverTool|DynamicTool|Tool|StructuredTool|Runnable-seqToolNode_0-seqToolNode_0-input-tools-Tool"
    },
    {
      "source": "seqToolNode_0",
      "sourceHandle": "seqToolNode_0-output-seqToolNode-ToolNode",
      "target": "seqLLMNode_1",
      "targetHandle": "seqLLMNode_1-input-sequentialNode-Start | Agent | Condition | LLMNode | ToolNode | CustomFunction | ExecuteFlow",
      "type": "buttonedge",
      "id": "seqToolNode_0-seqToolNode_0-output-seqToolNode-ToolNode-seqLLMNode_1-seqLLMNode_1-input-sequentialNode-Start | Agent | Condition | LLMNode | ToolNode | CustomFunction | ExecuteFlow"
    },
    {
      "source": "seqLLMNode_1",
      "sourceHandle": "seqLLMNode_1-output-seqLLMNode-LLMNode",
      "target": "seqEnd_0",
      "targetHandle": "seqEnd_0-input-sequentialNode-Agent | Condition | LLMNode | ToolNode | CustomFunction | ExecuteFlow",
      "type": "buttonedge",
      "id": "seqLLMNode_1-seqLLMNode_1-output-seqLLMNode-LLMNode-seqEnd_0-seqEnd_0-input-sequentialNode-Agent | Condition | LLMNode | ToolNode | CustomFunction | ExecuteFlow"
    }
  ]
}